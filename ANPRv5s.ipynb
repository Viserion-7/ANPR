{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install roboflow\n",
    "%pip install opencv-python-headless\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install pyyaml\n",
    "%pip install tqdm\n",
    "%pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"xx\")\n",
    "# project = rf.workspace(\"roboflow-universe-projects\").project(\"license-plate-recognition-rxg4e\")\n",
    "# version = project.version(4)\n",
    "# dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset 2\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"xx\")\n",
    "# project = rf.workspace(\"augmented-startups\").project(\"vehicle-registration-plates-trudk\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo=YOLO(\"weights/yolov5su.pt\")\n",
    "# yolo.train(data=\"License-Plate-Recognition-4/data.yaml\", epochs=30, batch=-1)\n",
    "# valid_results=yolo.val()\n",
    "# print(\"Validation Results\")\n",
    "# print(valid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo=YOLO(\"runs_1/detect/train7/weights/last.pt\")\n",
    "# yolo.train(data=\"Vehicle-Registration-Plates-1/data.yaml\", epochs=30, batch=-1)\n",
    "# valid_results=yolo.val()\n",
    "# print(\"Validation Results\")\n",
    "# print(valid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_bbox(image, results):\n",
    "\tclasses = results.names\n",
    "\tif isinstance(image, str):\n",
    "\t\timage = Image.open(image)\n",
    "\t\timage = np.array(image)\n",
    "\n",
    "\tfor i in range(len(results.boxes)):\n",
    "\t\tbox = results.boxes[i]\n",
    "\t\ttensor = box.xyxy[0]\n",
    "\t\tif box.cls in [2,3,5,7]:\n",
    "\t\t\tclassname = classes[int(box.cls)]\n",
    "\t\t\tx1 = int(tensor[0].item())\n",
    "\t\t\ty1 = int(tensor[1].item())\n",
    "\t\t\tx2 = int(tensor[2].item())\n",
    "\t\t\ty2 = int(tensor[3].item())\n",
    "\t\t\tcv2.rectangle(image,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "\t\t\t# cv2.putText(image, classname, (int(x1) + 5, int(y1) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,255), 2)\n",
    "\treturn image\n",
    "\n",
    "def predict_image(model, image):\n",
    "\tresults = model.predict(image)[0]\n",
    "\timage = draw_bbox(image, results)\n",
    "\treturn image\n",
    "\n",
    "def process_video(model, input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to PIL Image for prediction\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Predict and draw bounding boxes\n",
    "        results = model.predict(image)[0]\n",
    "        frame = draw_bbox(np.array(image), results)\n",
    "        \n",
    "        # Write the frame into the output video\n",
    "        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved as {output_path}\")\n",
    "\n",
    "def forward(img):\n",
    "        out_img = np.copy(img)\n",
    "        img = cv2.resize(img, (out_img.shape[1], out_img.shape[0]))\n",
    "        return out_img\n",
    "\n",
    "\n",
    "def process_stream(model, input_stream):\n",
    "    cap = cv2.VideoCapture(input_stream)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        frame_count += 1\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            out_frame = forward(frame)\n",
    "            out_frame = cv2.resize(out_frame, (640, 480))\n",
    "            if frame_count % 1 == 0:\n",
    "                out_frame = predict_image(model, out_frame)\n",
    "            cv2.imshow('Number Plate Detection', out_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"weights/yolov8x.pt\")\n",
    "# predict_image(model, \"License-Plate-Recognition-4/test/images/xemayBigPlate48_jpg.rf.f1383185ead4cbc0663c837ee7c884ed.jpg\")\n",
    "path = \"1.mp4\"\n",
    "process_video(model, \"Video/\"+path, \"Video/Predict/\"+path)\n",
    "path = \"2.mp4\"\n",
    "process_video(model, \"Video/\"+path, \"Video/Predict/\"+path)\n",
    "# process_stream(model, \"License-Plate-Recognition-4/Video/\"+path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"runs_1/detect/train7/weights/best.pt\")\n",
    "# predict_image(model, \"License-Plate-Recognition-4/test/images/xemayBigPlate48_jpg.rf.f1383185ead4cbc0663c837ee7c884ed.jpg\")\n",
    "# path = \"2.mp4\"\n",
    "# # process_video(model, \"License-Plate-Recognition-4/Video/\"+path, \"License-Plate-Recognition-4/Video/Predict/\"+path)\n",
    "# process_stream(model, \"License-Plate-Recognition-4/Video/\"+path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "# predict_image(model, \"Vehicle-Registration-Plates-1/test/images/00a7d31c6cc6b7f3_jpg.rf.805219027ce99b4baa1deaba3679211b.jpg\")\n",
    "# path = \"2.mp4\"\n",
    "# # process_video(model, \"Vehicle-Registration-Plates-1/Video\"+path, \"License-Plate-Recognition-4/Video/Predict/\"+path)\n",
    "# process_stream(model, \"Vehicle-Registration-Plates-1/Video/\"+path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
